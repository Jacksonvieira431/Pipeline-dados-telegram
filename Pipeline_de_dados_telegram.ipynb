{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline de dados com Telegram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrXFaIl-0ryz"
      },
      "source": [
        "![modulo_43-4.png](Roadmap-projeto-pipelane-de-dados-telegram.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ3AdveuEJyi"
      },
      "source": [
        " - **Telegram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSm8cfvAFmKJ"
      },
      "source": [
        "As mensagens captadas por um *bot* podem ser acessadas via API. A única informação necessária é o `token` de acesso fornecido pelo `BotFather` na criação do *bot*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWgCOxH6FmKS"
      },
      "source": [
        "> **Nota:** A documentação completa da API pode ser encontrada neste [link](https://core.telegram.org/bots/api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz6y8ROkV92M",
        "outputId": "73fac31d-ec2e-43f5-dd4a-f100351cec16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "token = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CUofqbwV92N"
      },
      "source": [
        "A `url` base é comum a todos os métodos da API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSNVqUZEV92N"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "base_url = f'https://api.telegram.org/bot{token}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvHUmCcAFmKY"
      },
      "source": [
        "- **getMe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O17cMTP1FmKY"
      },
      "source": [
        "O método `getMe` retorna informações sobre o *bot*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saxm4DICV92O",
        "outputId": "1e4ca889-ec9c-47b2-c573-e7b60aac0a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ok\": true,\n",
            "  \"result\": {\n",
            "    \"id\": 6545017835,\n",
            "    \"is_bot\": true,\n",
            "    \"first_name\": \"Jack_pipeline_bot\",\n",
            "    \"username\": \"Jack_pipeline_bot\",\n",
            "    \"can_join_groups\": false,\n",
            "    \"can_read_all_group_messages\": false,\n",
            "    \"supports_inline_queries\": false\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(url=f'{base_url}/getMe')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34uFkaArFmKZ"
      },
      "source": [
        " - **getUpdates**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkKNp0UwFmKa"
      },
      "source": [
        "O método `getMe` retorna as mensagens captadas pelo *bot*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ZfS-RNV92Q",
        "outputId": "dde69b0f-c722-4885-e7b7-df491e0ff798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ok\": false,\n",
            "  \"error_code\": 409,\n",
            "  \"description\": \"Conflict: can't use getUpdates method while webhook is active; use deleteWebhook to delete the webhook first\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = requests.get(url=f'{base_url}/getUpdates')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3jThgmVV91_"
      },
      "source": [
        "## 1\\. Ingestão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxMY-mKLV92D"
      },
      "source": [
        "A etapa de **ingestão** é responsável, como seu o próprio nome diz, pela ingestão dos dados transacionais em ambientes analíticos. De maneira geral, o dado ingerido é persistido no formato mais próximo do original, ou seja, nenhuma transformação é realizada em seu conteúdo ou estrutura (*schema*). Como exemplo, dados de uma API *web* que segue o formato REST (*representational state transfer*) são entregues, logo, persistidos, no formato JSON."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XU2HYiTVgry"
      },
      "source": [
        "> Persistir os dados em seu formato original trás muitas vantagens, como a possibilidade de reprocessamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-OPtk87UFH-"
      },
      "source": [
        "Pode ser conduzida de duas formas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfj9zCtpS_Zj"
      },
      "source": [
        " - **Batch**: blocos de dados são ingeridos em uma frequência bem definida, geralmente na escala de horas ou dias;\n",
        " - **Streaming**: dados são ingeridos conforme são produzidos e disponibilizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7CfG9TsUgll"
      },
      "source": [
        "No projeto, as mensagens capturadas pelo *bot* podem ser ingeridas através da API *web* de *bots* do **Telegram**, portanto são fornecidos no formato JSON. Como o **Telegram** retem mensagens por apenas 24h em seus servidores, a ingestão via **streaming** é a mais indicada. Para que seja possível esse tipo de **ingestão** seja possível, vamos utilizar um *webhook* (gancho *web*), ou seja, vamos redirecionar as mensagens automaticamente para outra API *web*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJKKD2FNaVnW"
      },
      "source": [
        "Sendo assim, precisamos de um serviço da AWS que forneça um API *web* para receber os dados redirecionados, o `AWS API Gateway` (documentação neste [link](https://docs.aws.amazon.com/pt_br/apigateway/latest/developerguide/welcome.html)). Dentre suas diversas funcionalidades, o `AWS API Gateway` permite o redirecionamento do dado recebido para outros serviços da AWS. Logo, vamos conecta-lo ao `AWS Lambda`, que pode sua vez, irá armazenar o dado em seu formato original (JSON) em um *bucket* do `AWS S3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tllc_bXk5PZS"
      },
      "source": [
        "> Sistemas que reagem a eventos são conhecidos como *event-driven*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4DRjMhC5O2p"
      },
      "source": [
        "Portanto, precisamos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLlOMVSLYEJO"
      },
      "source": [
        " - Criar um *bucket* no `AWS S3`;\n",
        " - Criar uma função no `AWS Lambda`;\n",
        " - Criar uma API *web* no `AWS API Gateway`;\n",
        " - Configurar o *webhook* da API de *bots* do **Telegram**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rg_hCCBXZfE"
      },
      "source": [
        "### **1.1. AWS S3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71p8nQzDXdu6"
      },
      "source": [
        "Na etapa de **ingestão**, o `AWS S3` tem a função de passivamente armazenar as mensagens captadas pelo *bot* do **Telegram** no seu formato original: JSON. Para tanto, basta a criação de um *bucket*. Como padrão, vamos adicionar o sufixo `-raw` ao seu nome (vamos seguir esse padrão para todos os serviços desta camada)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvFQD6a5dT3Z"
      },
      "source": [
        "> **Nota**: um `data lake` é o nome dado a um repositório de um grande volume dados. É organizado em zonas que armazenam replicadas dos dados em diferentes níveis de processamento. A nomenclatura das zonas varia, contudo, as mais comuns são: *raw* e *enriched* ou *bronze*, *silver* e *gold*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d_b7dYsV92E"
      },
      "source": [
        "### **1.2. AWS Lambda**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcIaQiwrQPEQ"
      },
      "source": [
        "Na etapa de **ingestão**, o `AWS Lambda` tem a função de ativamente persistir as mensagens captadas pelo *bot* do **Telegram** em um *bucket* do `AWS S3`. Para tanto vamos criar uma função que opera da seguinte forma:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUsOUiAsjIK8"
      },
      "source": [
        " - Recebe a mensagem no parâmetro `event`;\n",
        " - Verifica se a mensagem tem origem no grupo do **Telegram** correto;\n",
        " - Persiste a mensagem no formato JSON no *bucket* do `AWS S3`;\n",
        " - Retorna uma mensagem de sucesso (código de retorno HTTP igual a 200) a API de *bots* do **Telegram**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4DF0UkBsUbF"
      },
      "source": [
        "> **Nota**: No **Telegram**, restringimos a opção de adicionar o *bot* a grupos, contudo, ainda é possível iniciar uma conversa em um *chat* privado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgrxaVwrp3B-"
      },
      "source": [
        "O código da função:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D0htY5kebM4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import boto3\n",
        "\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> dict:\n",
        "\n",
        "  '''\n",
        "  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n",
        "  seu conteúdo se foi produzida em um determinado grupo e a escreve,\n",
        "  em seu formato original JSON, em um bucket do AWS S3.\n",
        "  '''\n",
        "\n",
        "  # vars de ambiente\n",
        "\n",
        "  BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n",
        "\n",
        "  # vars lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  filename = f'{timestamp}.json'\n",
        "\n",
        "  # código principal\n",
        "\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "    message = json.loads(event[\"body\"])\n",
        "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
        "\n",
        "    if chat_id == TELEGRAM_CHAT_ID:\n",
        "\n",
        "      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
        "        json.dump(message, fp)\n",
        "\n",
        "      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return dict(statusCode=\"500\")\n",
        "\n",
        "  else:\n",
        "      return dict(statusCode=\"200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A379qszF7mC"
      },
      "source": [
        "Para que a função funcione corretamente, algumas configurações precisam ser realizadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOJKm38F7mD"
      },
      "source": [
        " - **Variáveis de ambiente**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ntVsSinP1T"
      },
      "source": [
        "Note que o código exige a configuração de duas variáveis de ambiente: `AWS_S3_BUCKET` com o nome do *bucket* do `AWS S3` e `TELEGRAM_CHAT_ID` com o id do *chat* do grupo do **Telegram**. Para adicionar variáveis de ambiente em uma função do `AWS Lambda`, basta acessar configurações -> variáveis de ambiente no console da função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNVZulWFnnt3"
      },
      "source": [
        "> **Nota**: Variáveis de ambiente são excelentes formas de armazenar informações sensíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zzzcFCaF9rQ"
      },
      "source": [
        " - **Permissão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z67UTJvYDZDH"
      },
      "source": [
        "Por fim, precisamos adicionar a permissão de escrita no *bucket* do `AWS S3` para a função do `AWS Lambda` no `AWS IAM`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvaddHeBV92J"
      },
      "source": [
        "### **1.3. AWS API Gateway**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkOlO04qQVOT"
      },
      "source": [
        "Na etapa de **ingestão**, o `AWS API Gateway` tem a função de receber as mensagens captadas pelo *bot* do **Telegram**, enviadas via *webhook*, e iniciar uma função do `AWS Lambda`, passando o conteúdo da mensagem no seu parâmetro *event*. Para tanto vamos criar uma API e configurá-la como gatilho da função do `AWS Lambda`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiMeNmZ8HGJU"
      },
      "source": [
        " - Acesse o serviço e selecione: *Create API* -> *REST API*;\n",
        " - Insira um nome, como padrão, um que termine com o sufixo `-api`;\n",
        " - Selecione: *Actions* -> *Create Method* -> *POST*;\n",
        " - Na tela de *setup*:\n",
        "  - Selecione *Integration type* igual a *Lambda Function*;\n",
        "  - Habilite o *Use Lambda Proxy integration*;\n",
        "  - Busque pelo nome a função do `AWS Lambda`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0LSPI7F6Ixv"
      },
      "source": [
        "Podemos testar a integração com o `AWS Lambda` através da ferramenta de testes do serviço. Por fim, vamos fazer a implantação da API e obter o seu endereço *web*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joosbL1XFLuw"
      },
      "source": [
        " - Selecione: *Actions* -> *Deploy API*;\n",
        " - Selecione: *New Stage* para *Deployment stage*;\n",
        " - Adicione *dev* como `Stage name`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sKaErRFGeR8"
      },
      "source": [
        "Copie o a `url` gerada na variável `aws_api_gateway_url`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0lOp3f4AC-",
        "outputId": "39945be1-5515-4809-c7f2-c1e5ddfc3a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "aws_api_gateway_url = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUwMI-1WV92M"
      },
      "source": [
        "### **1.4. Telegram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qemcWsJV92M"
      },
      "source": [
        "Vamos configurar o *webhook* para redirecionar as mensagens para a `url` do `AWS API Gateway`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0R9M-ZZV92P"
      },
      "source": [
        " - **setWebhook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_bTFFGdV92P"
      },
      "source": [
        "O método `setWebhook` configura o redirecionamento das mensagens captadas pelo *bot* para o endereço *web* do paramametro `url`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSHPqn1wb_o-"
      },
      "source": [
        "> **Nota**: os métodos `getUpdates` e `setWebhook` são mutualmente exclusivos, ou seja, enquanto o *webhook* estiver ativo, o método `getUpdates` não funcionará. Para desativar o *webhook*, basta utilizar o método `deleteWebhook`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg4BCC44avB-",
        "outputId": "52c71f05-c69d-4793-b7ce-ab8e34aca3db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ok\": true,\n",
            "  \"result\": true,\n",
            "  \"description\": \"Webhook was set\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = requests.get(url=f'{base_url}/setWebhook?url={aws_api_gateway_url}')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUmrHupw3kqX"
      },
      "source": [
        " - **getWebhookInfo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7cjJ3tL3xDV"
      },
      "source": [
        "O método `getWebhookInfo` retorna as informações sobre o *webhook* configurado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D3O01qH3tVV",
        "outputId": "e5858654-6102-476f-9da8-dd5063279064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ok\": true,\n",
            "  \"result\": {\n",
            "    \"url\": \"https://rjof9ea5gh.execute-api.sa-east-1.amazonaws.com/dev\",\n",
            "    \"has_custom_certificate\": false,\n",
            "    \"pending_update_count\": 0,\n",
            "    \"max_connections\": 40,\n",
            "    \"ip_address\": \"54.94.25.200\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = requests.get(url=f'{base_url}/getWebhookInfo')\n",
        "\n",
        "print(json.dumps(json.loads(response.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvJTE2FpaGeU"
      },
      "source": [
        "## 2\\. ETL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO5ewoGuZcWq"
      },
      "source": [
        "A etapa de **extração, transformação e carregamento** (do inglês *extraction, transformation and load* ou **ETL**) é uma etapa abrangente responsável pela manipulação dos dados ingeridos de sistemas transacionais, ou seja, já persistidos em camadas cruas ou *raw* de sistemas analíticos. Os processos conduzidos nesta etapa variam bastante de acordo com a área da empresa, do volume/variedade/velocidade do dado consumido, etc. Contudo, em geral, o dado cru ingerido passa por um processo recorrente de *data wrangling* onde o dado é limpo, deduplicado, etc. e persistido com técnicas de particionamento, orientação a coluna e compressão. Por fim, o dado processado está pronto para ser analisado por profissionais de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ox-j0vkX1Rd"
      },
      "source": [
        "No projeto, as mensagens de um único dia, persistidas na camada cru, serão compactas em um único arquivo, orientado a coluna e comprimido, que será persistido em uma camada enriquecida. Além disso, durante este processo, o dado também passará por etapas de *data wrangling*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGzZqlFvZmN8"
      },
      "source": [
        "Para isso, vamos utilizar uma função do `AWS Lambda` como motor de processamento e um *bucket* do `AWS S3` como camada enriquecida para a persistência do dado processado. Para garantir a recorrência, vamos configurar uma regra do `AWS Event Bridge` como gatilho diáro da função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpcMVz90mY5o"
      },
      "source": [
        "### **2.1. AWS S3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dpLiSZdH_bC"
      },
      "source": [
        "Na etapa de **ETL**, o `AWS S3` tem a função de passivamente armazenar as mensagens processadas de um dia em um único arquivo no formato Parquet. Para tanto, basta a criação de um *bucket*. Como padrão, vamos adicionar o sufixo `-enriched` ao seu nome (vamos seguir esse padrão para todos os serviços desta camada)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ2mfpx7H_bE"
      },
      "source": [
        "> **Nota**: um `data lake` é o nome dado a um repositório de um grande volume dados. É organizado em zonas que armazenam replicadas dos dados em diferentes níveis de processamento. A nomenclatura das zonas varia, contudo, as mais comuns são: *raw* e *enriched* ou *bronze*, *silver* e *gold*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47BwfLAamRc0"
      },
      "source": [
        "### **2.2. AWS Lambda**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeS09KecK4q"
      },
      "source": [
        "Na etapa de **ETL**, o `AWS Lambda` tem a função de ativamente processar as mensagens captadas pelo *bot* do **Telegram**, persistidas na camada cru no *bucket* do `AWS S3`, e persisti-las na camada enriquecida, também em um *bucket* do `AWS S3`. Logo, vamos criar uma função que opera da seguinte forma:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osapdBzhcK4s"
      },
      "source": [
        " - Lista todos os arquivos JSON de uma única participação da camada crua de um *bucket* do `AWS S3`;\n",
        " - Para cada arquivo listado:\n",
        "  - Faz o *download* do arquivo e carrega o conteúdo da mensagem;\n",
        "  - Executa uma função de *data wrangling*;\n",
        "  - Cria uma tabela do PyArrow e a contatena com as demais.\n",
        " - Persiste a tabela no formato Parquet na camada enriquecida em um *bucket* do `AWS S3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpLN2FmMng1L"
      },
      "source": [
        "> **Nota**: O fato de utilizarmos duas camadas de armazenamento e processamento, permite que possamos reprocessar os dados crus de diversas maneiras, quantas vezes forem preciso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-qsGM8fB72O"
      },
      "source": [
        "> **Nota**: Atente-se ao fato de que a função processa as mensagens do dia anterior (D-1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNOS0msDQwfg"
      },
      "source": [
        "O código da função:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6EBaPdDKlGj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "import boto3\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> bool:\n",
        "\n",
        "  '''\n",
        "  Diariamente é executado para compactar as diversas mensagensm, no formato\n",
        "  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único\n",
        "  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n",
        "  '''\n",
        "\n",
        "  # vars de ambiente\n",
        "\n",
        "  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n",
        "  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n",
        "\n",
        "  # vars lógicas\n",
        "\n",
        "  tzinfo = timezone(offset=timedelta(hours=-3))\n",
        "  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "  # código principal\n",
        "\n",
        "  table = None\n",
        "  client = boto3.client('s3')\n",
        "\n",
        "  try:\n",
        "\n",
        "      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n",
        "\n",
        "      for content in response['Contents']:\n",
        "\n",
        "        key = content['Key']\n",
        "        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n",
        "\n",
        "        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n",
        "\n",
        "          data = json.load(fp)\n",
        "          data = data[\"message\"]\n",
        "\n",
        "        parsed_data = parse_data(data=data)\n",
        "        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n",
        "\n",
        "        if table:\n",
        "\n",
        "          table = pa.concat_tables([table, iter_table])\n",
        "\n",
        "        else:\n",
        "\n",
        "          table = iter_table\n",
        "          iter_table = None\n",
        "\n",
        "      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n",
        "      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n",
        "\n",
        "      return True\n",
        "\n",
        "  except Exception as exc:\n",
        "      logging.error(msg=exc)\n",
        "      return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltObFX9dmo4L"
      },
      "source": [
        "O código da função de *data wrangling*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlemgNT-JEfE"
      },
      "outputs": [],
      "source": [
        "def parse_data(data: dict) -> dict:\n",
        "\n",
        "  date = datetime.now().strftime('%Y-%m-%d')\n",
        "  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "  parsed_data = dict()\n",
        "\n",
        "  for key, value in data.items():\n",
        "\n",
        "      if key == 'from':\n",
        "          for k, v in data[key].items():\n",
        "              if k in ['id', 'is_bot', 'first_name']:\n",
        "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "      elif key == 'chat':\n",
        "          for k, v in data[key].items():\n",
        "              if k in ['id', 'type']:\n",
        "                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "      elif key in ['message_id', 'date', 'text']:\n",
        "          parsed_data[key] = [value]\n",
        "\n",
        "  if not 'text' in parsed_data.keys():\n",
        "    parsed_data['text'] = [None]\n",
        "\n",
        "  return parsed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2NV3mRlo29J"
      },
      "source": [
        "Para que a função funcione corretamente, algumas configurações precisam ser realizadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pIm9PQrpEJ5"
      },
      "source": [
        " - **Variáveis de ambiente**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2RcNMiKoziS"
      },
      "source": [
        "Note que o código exige a configuração de duas variáveis de ambiente: `AWS_S3_BUCKET` e `AWS_S3_ENRICHED` com os nomes dos *bucket* do `AWS S3` da camada cru e enriquecida, respectivamente. Para adicionar variáveis de ambiente em uma função do `AWS Lambda`, basta acessar configurações -> variáveis de ambiente no console da função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XthkP2-py8b"
      },
      "source": [
        " - **Permissão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSedFVXoozif"
      },
      "source": [
        "Precisamos adicionar a permissão de escrita nos *buckets* do `AWS S3` para a função do `AWS Lambda` no `AWS IAM`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnIH5uJ8wmt9"
      },
      "source": [
        " - **Recursos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLuZHKRzekjf"
      },
      "source": [
        "O *timeout* padrão de funcões do `AWS Lambda` é de 3 segundos. Para a função, vamos aumentar o tempo para 5 minutos, principalmente para lidar com o IO (*input/output*) de arquivos do `AWS S3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsz46lGkyxAk"
      },
      "source": [
        " - **Camadas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43f1ulYOyzoZ"
      },
      "source": [
        "Por fim, note que o código da função utiliza o pacote Python PyArrow. Contudo, o ambiente padrão do `AWS Lambda` possui poucos pacotes externos instalado, como o pacote Python boto3, logo o PyArrow não será encontrado e a execução da função falhará. Existem algumas formas de adicionar pacotes externos no ambiente de execução do AWS Lambda, um deles é a criação de camadas ou *layers*, onde podemos fazer o *upload* dos pacotes Python direto na plataforma ou através de um *bucket* do `AWS S3`. Vamos então seguir com a última opção, onde teremos que:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzr70MKQAoOg"
      },
      "source": [
        " - Criar um *bucket* no `AWS S3`;\n",
        " - Fazer o *upload* do código do pacote Python do PyArrow (*download* neste [link](https://github.com/awslabs/aws-data-wrangler/releases));\n",
        " - Criar *layer* e conectar na função."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvispzZRQy40"
      },
      "source": [
        "### **2.3. AWS Event Bridge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOr4539pQy41"
      },
      "source": [
        "Na etapa de **ETL**, o `AWS Event Bridge` tem a função de ativar diariamente a fun\bção de **ETL** do `AWS Lambda`, funcionando assim como um *scheduler*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngNtS-ruCKpG"
      },
      "source": [
        "> **Nota**: Atente-se ao fato de que a função processa as mensagens do dia anterior (D-1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BtM1Gk4Q40A"
      },
      "source": [
        "## 3\\. Apresentação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z6XphlWQ40B"
      },
      "source": [
        "A etapa de **apresentação** é reponsável por entregar o dado para os usuários (analistas, cientistas, etc.) e sistemas (dashboards, motores de consultas, etc.), idealmente através de uma interface de fácil uso, como o SQL, logo, essa é a única etapa que a maioria dos usuários terá acesso. Além disso, é importante que as ferramentas da etapa entregem dados armazenados em camadas refinadas, pois assim as consultas são mais baratas e o dados mais consistentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN1tLjfUQ40B"
      },
      "source": [
        "### **3.1. AWS Athena**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws97sO4LQ40B"
      },
      "source": [
        "Na etapa de **apresentação**, o `AWS Athena` tem função de entregar o dados através de uma interface SQL para os usuários do sistema analítico. Para criar a interface, basta criar uma tabela externa sobre o dado armazenado na camada mais refinada da arquitetura, a camada enriquecida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjsrFaxafJnB"
      },
      "source": [
        "```sql\n",
        "CREATE EXTERNAL TABLE `telegram`(\n",
        "  `message_id` bigint,\n",
        "  `user_id` bigint,\n",
        "  `user_is_bot` boolean,\n",
        "  `user_first_name` string,\n",
        "  `chat_id` bigint,\n",
        "  `chat_type` string,\n",
        "  `text` string,\n",
        "  `date` bigint)\n",
        "PARTITIONED BY (\n",
        "  `context_date` date)\n",
        "ROW FORMAT SERDE\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
        "STORED AS INPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n",
        "OUTPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
        "LOCATION\n",
        "  's3://<bucket-enriquecido>/'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QOVPPi6Olsl"
      },
      "source": [
        "Por fim, adicione as partições disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFKdAPuTNO5Q"
      },
      "source": [
        "> **Importante**: Toda vez que uma nova partição é adicionada ao repositório de dados, é necessário informar o `AWS Athena` para que a ela esteja disponível via SQL. Para isso, use o comando SQL `MSCK REPAIR TABLE <nome-tabela>` para todas as partições (mais caro) ou `ALTER TABLE <nome-tabela> ADD PARTITION <coluna-partição> = <valor-partição>` para uma única partição (mais barato), documentação neste [link](https://docs.aws.amazon.com/athena/latest/ug/alter-table-add-partition.html))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_XiPFyOOxze"
      },
      "source": [
        "```sql\n",
        "MSCK REPAIR TABLE `telegram`;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7ixVPgZO0ea"
      },
      "source": [
        "E consulte as 10 primeiras linhas para observar o resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krcRJ4OcO6tX"
      },
      "source": [
        "```sql\n",
        "SELECT * FROM `telegram` LIMIT 10;\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
